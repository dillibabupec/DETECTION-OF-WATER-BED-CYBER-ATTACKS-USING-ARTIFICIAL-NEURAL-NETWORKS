{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45ba246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41115fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>F_PU2</th>\n",
       "      <th>S_PU2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.39</td>\n",
       "      <td>93.63</td>\n",
       "      <td>93.65</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>70.00</td>\n",
       "      <td>28.22</td>\n",
       "      <td>85.87</td>\n",
       "      <td>21.69</td>\n",
       "      <td>82.72</td>\n",
       "      <td>21.58</td>\n",
       "      <td>71.99</td>\n",
       "      <td>39.33</td>\n",
       "      <td>29.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.66</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.53</td>\n",
       "      <td>89.41</td>\n",
       "      <td>89.43</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.73</td>\n",
       "      <td>24.45</td>\n",
       "      <td>84.87</td>\n",
       "      <td>29.81</td>\n",
       "      <td>86.62</td>\n",
       "      <td>29.81</td>\n",
       "      <td>59.76</td>\n",
       "      <td>42.17</td>\n",
       "      <td>26.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.11</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.15</td>\n",
       "      <td>3.22</td>\n",
       "      <td>89.88</td>\n",
       "      <td>89.89</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.29</td>\n",
       "      <td>23.90</td>\n",
       "      <td>87.11</td>\n",
       "      <td>29.85</td>\n",
       "      <td>87.64</td>\n",
       "      <td>29.85</td>\n",
       "      <td>58.50</td>\n",
       "      <td>42.00</td>\n",
       "      <td>25.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.04</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>88.10</td>\n",
       "      <td>88.12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.98</td>\n",
       "      <td>27.10</td>\n",
       "      <td>68.75</td>\n",
       "      <td>31.60</td>\n",
       "      <td>64.25</td>\n",
       "      <td>31.47</td>\n",
       "      <td>72.30</td>\n",
       "      <td>43.24</td>\n",
       "      <td>28.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.08</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.46</td>\n",
       "      <td>87.01</td>\n",
       "      <td>87.03</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.11</td>\n",
       "      <td>26.76</td>\n",
       "      <td>68.74</td>\n",
       "      <td>32.30</td>\n",
       "      <td>64.23</td>\n",
       "      <td>32.17</td>\n",
       "      <td>72.53</td>\n",
       "      <td>44.00</td>\n",
       "      <td>28.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  F_PU2  S_PU2  ...  P_J256  \\\n",
       "0  2.44  5.24  3.19  4.10  2.86  5.50  4.39  93.63  93.65      1  ...   70.00   \n",
       "1  2.66  4.53  3.20  4.18  3.29  5.44  4.53  89.41  89.43      1  ...   87.73   \n",
       "2  3.11  3.66  3.66  4.21  3.87  5.15  3.22  89.88  89.89      1  ...   89.29   \n",
       "3  3.62  3.04  4.17  4.04  3.56  4.98  2.40  88.10  88.12      1  ...   91.98   \n",
       "4  4.08  2.68  4.73  3.20  3.11  5.39  3.46  87.01  87.03      1  ...   92.11   \n",
       "\n",
       "   P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  ATT_FLAG  \n",
       "0   28.22   85.87   21.69   82.72   21.58   71.99  39.33   29.64         0  \n",
       "1   24.45   84.87   29.81   86.62   29.81   59.76  42.17   26.15         0  \n",
       "2   23.90   87.11   29.85   87.64   29.85   58.50  42.00   25.56         0  \n",
       "3   27.10   68.75   31.60   64.25   31.47   72.30  43.24   28.38         0  \n",
       "4   26.76   68.74   32.30   64.23   32.17   72.53  44.00   28.04         0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('A.csv')\n",
    "del df['DATETIME']\n",
    "del df['F_PU9']\n",
    "del df['S_PU9']\n",
    "del df['F_PU5']\n",
    "del df['S_PU5']\n",
    "del df['F_PU3']\n",
    "del df['S_PU3']\n",
    "del df['S_PU1']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffc2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd41d833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATT_FLAG\n",
       "0    3685\n",
       "1     492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ATT_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d6fa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7', 'F_PU1',\n",
       "       'F_PU2', 'S_PU2', 'F_PU4', 'S_PU4', 'F_PU6', 'S_PU6', 'F_PU7', 'S_PU7',\n",
       "       'F_PU8', 'S_PU8', 'F_PU10', 'S_PU10', 'F_PU11', 'S_PU11', 'F_V2',\n",
       "       'S_V2', 'P_J280', 'P_J269', 'P_J300', 'P_J256', 'P_J289', 'P_J415',\n",
       "       'P_J302', 'P_J306', 'P_J307', 'P_J317', 'P_J14', 'P_J422', 'ATT_FLAG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b7f3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>F_PU2</th>\n",
       "      <th>S_PU2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.39</td>\n",
       "      <td>93.63</td>\n",
       "      <td>93.65</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>70.00</td>\n",
       "      <td>28.22</td>\n",
       "      <td>85.87</td>\n",
       "      <td>21.69</td>\n",
       "      <td>82.72</td>\n",
       "      <td>21.58</td>\n",
       "      <td>71.99</td>\n",
       "      <td>39.33</td>\n",
       "      <td>29.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.66</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.53</td>\n",
       "      <td>89.41</td>\n",
       "      <td>89.43</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.73</td>\n",
       "      <td>24.45</td>\n",
       "      <td>84.87</td>\n",
       "      <td>29.81</td>\n",
       "      <td>86.62</td>\n",
       "      <td>29.81</td>\n",
       "      <td>59.76</td>\n",
       "      <td>42.17</td>\n",
       "      <td>26.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.11</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.15</td>\n",
       "      <td>3.22</td>\n",
       "      <td>89.88</td>\n",
       "      <td>89.89</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.29</td>\n",
       "      <td>23.90</td>\n",
       "      <td>87.11</td>\n",
       "      <td>29.85</td>\n",
       "      <td>87.64</td>\n",
       "      <td>29.85</td>\n",
       "      <td>58.50</td>\n",
       "      <td>42.00</td>\n",
       "      <td>25.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.04</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>88.10</td>\n",
       "      <td>88.12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.98</td>\n",
       "      <td>27.10</td>\n",
       "      <td>68.75</td>\n",
       "      <td>31.60</td>\n",
       "      <td>64.25</td>\n",
       "      <td>31.47</td>\n",
       "      <td>72.30</td>\n",
       "      <td>43.24</td>\n",
       "      <td>28.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.08</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.46</td>\n",
       "      <td>87.01</td>\n",
       "      <td>87.03</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.11</td>\n",
       "      <td>26.76</td>\n",
       "      <td>68.74</td>\n",
       "      <td>32.30</td>\n",
       "      <td>64.23</td>\n",
       "      <td>32.17</td>\n",
       "      <td>72.53</td>\n",
       "      <td>44.00</td>\n",
       "      <td>28.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  F_PU2  S_PU2  ...  P_J256  \\\n",
       "0  2.44  5.24  3.19  4.10  2.86  5.50  4.39  93.63  93.65      1  ...   70.00   \n",
       "1  2.66  4.53  3.20  4.18  3.29  5.44  4.53  89.41  89.43      1  ...   87.73   \n",
       "2  3.11  3.66  3.66  4.21  3.87  5.15  3.22  89.88  89.89      1  ...   89.29   \n",
       "3  3.62  3.04  4.17  4.04  3.56  4.98  2.40  88.10  88.12      1  ...   91.98   \n",
       "4  4.08  2.68  4.73  3.20  3.11  5.39  3.46  87.01  87.03      1  ...   92.11   \n",
       "\n",
       "   P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  ATT_FLAG  \n",
       "0   28.22   85.87   21.69   82.72   21.58   71.99  39.33   29.64         0  \n",
       "1   24.45   84.87   29.81   86.62   29.81   59.76  42.17   26.15         0  \n",
       "2   23.90   87.11   29.85   87.64   29.85   58.50  42.00   25.56         0  \n",
       "3   27.10   68.75   31.60   64.25   31.47   72.30  43.24   28.38         0  \n",
       "4   26.76   68.74   32.30   64.23   32.17   72.53  44.00   28.04         0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45183d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df.drop(labels='ATT_FLAG', axis=1).values\n",
    "y1 = df.loc[:,'ATT_FLAG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979ba207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd44af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR DATASET COUNT         :  Counter({0: 3685, 1: 492})\n",
      "OVER SAMPLING DATA COUNT  :  Counter({0: 3685, 1: 3685})\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros =RandomOverSampler(random_state=42)\n",
    "x,y=ros.fit_resample(x1,y1)\n",
    "print(\"OUR DATASET COUNT         : \", Counter(y1))\n",
    "print(\"OVER SAMPLING DATA COUNT  : \", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ca2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TRAIN DATASET    :  5896\n",
      "NUMBER OF TEST DATASET      :  1474\n",
      "TOTAL NUMBER OF DATASET    :  7370\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42, stratify=y)\n",
    "print(\"NUMBER OF TRAIN DATASET    : \", len(x_train))\n",
    "print(\"NUMBER OF TEST DATASET      : \", len(x_test))\n",
    "print(\"TOTAL NUMBER OF DATASET    : \", len(x_train)+len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e2bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TRAIN DATASET    :  5896\n",
      "NUMBER OF TEST DATASET      :  1474\n",
      "TOTAL NUMBER OF DATASET    :  7370\n"
     ]
    }
   ],
   "source": [
    "print(\"NUMBER OF TRAIN DATASET    : \", len(y_train))\n",
    "print(\"NUMBER OF TEST DATASET      : \", len(y_test))\n",
    "print(\"TOTAL NUMBER OF DATASET    : \", len(y_train)+len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b0091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and labels to torch tensors\n",
    "features = torch.tensor(x, dtype=torch.float32)\n",
    "labels = torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf31e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the dataset into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b6cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create DataLoader for batch processing\n",
    "batch_size = 32\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "675f01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Define the neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97888740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the model and set hyperparameters\n",
    "input_size = 36\n",
    "hidden_size = 128\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MyModel(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize lists to store loss and accuracy for each epoch\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae52c924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Accuracy: 62.62%, Loss: 1.0968\n",
      "Epoch [2/20], Accuracy: 68.86%, Loss: 0.6228\n",
      "Epoch [3/20], Accuracy: 62.35%, Loss: 0.6120\n",
      "Epoch [4/20], Accuracy: 62.75%, Loss: 0.5837\n",
      "Epoch [5/20], Accuracy: 69.81%, Loss: 0.5800\n",
      "Epoch [6/20], Accuracy: 77.82%, Loss: 0.5491\n",
      "Epoch [7/20], Accuracy: 70.56%, Loss: 0.5574\n",
      "Epoch [8/20], Accuracy: 78.15%, Loss: 0.5516\n",
      "Epoch [9/20], Accuracy: 67.64%, Loss: 0.5333\n",
      "Epoch [10/20], Accuracy: 73.81%, Loss: 0.5219\n",
      "Epoch [11/20], Accuracy: 76.26%, Loss: 0.5264\n",
      "Epoch [12/20], Accuracy: 70.62%, Loss: 0.5350\n",
      "Epoch [13/20], Accuracy: 68.86%, Loss: 0.5045\n",
      "Epoch [14/20], Accuracy: 75.31%, Loss: 0.5340\n",
      "Epoch [15/20], Accuracy: 76.39%, Loss: 0.5189\n",
      "Epoch [16/20], Accuracy: 73.61%, Loss: 0.5126\n",
      "Epoch [17/20], Accuracy: 77.68%, Loss: 0.4976\n",
      "Epoch [18/20], Accuracy: 74.36%, Loss: 0.4892\n",
      "Epoch [19/20], Accuracy: 69.88%, Loss: 0.4806\n",
      "Epoch [20/20], Accuracy: 79.51%, Loss: 0.4858\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 6: Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    average_loss = running_loss / num_batches\n",
    "    \n",
    "    # Calculate accuracy at the end of each epoch\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_predictions = []\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(test_labels, test_predictions)\n",
    "        epoch_accuracies.append(accuracy)\n",
    "        epoch_losses.append(average_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Accuracy: {accuracy * 100:.2f}%, Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.train()  # Switch back to training mode\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f530f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a19b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
